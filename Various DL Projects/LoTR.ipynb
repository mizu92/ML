{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LoTR.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/mizunashi92/dlhub/blob/master/LoTR.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "TNg93pLu0mVK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "id": "TuHMq4OCPjAl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils.data_utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Udeq8QPjn1Pj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "262f17bb-f3b5-4e11-dd6a-fe7c7f24fca4"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!ls"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LotR.txt  sample_data  shakespeare_sonnets.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PbeyqAJd0pfq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "metadata": {
        "id": "Gok2OXHDPh0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "1a4d2eb0-5421-42dd-b43d-35405f94b88d"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#path = get_file('shakespeare-sonnets.txt', origin='https://www.dropbox.com/s/ikbwosxutqwkqr6/Lord%20of%20the%20Rings.txt')\n",
        "!wget https://www.dropbox.com/s/2ftmqg2dt1kz6ng/LotR.txt\n",
        "\n",
        "with io.open('LotR.txt', encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "print('corpus length:', len(text))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-08-27 11:03:27--  https://www.dropbox.com/s/2ftmqg2dt1kz6ng/LotR.txt\r\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\r\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/2ftmqg2dt1kz6ng/LotR.txt [following]\n",
            "--2018-08-27 11:03:27--  https://www.dropbox.com/s/raw/2ftmqg2dt1kz6ng/LotR.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc08533c0879967828e6bd675a52.dl.dropboxusercontent.com/cd/0/inline/AO9teeIJDUUcth_41OFkiiUYt5HVqLM-S4_hsj_XV6nzZot0vM-CeHOaEv8olmgzXj1D5aJ8hPAeC1qml70RhA5zQMkpSZSvW3Pym-p5wxhN6L0KQpawRRkUPTIWFl9JpAmRdrP8nR9E5MCMPVm55DOEN67Rg-CLwQDWn_SVGbCiOBQNPnicGe7Fsgs0n6tI3Y0/file [following]\n",
            "--2018-08-27 11:03:27--  https://uc08533c0879967828e6bd675a52.dl.dropboxusercontent.com/cd/0/inline/AO9teeIJDUUcth_41OFkiiUYt5HVqLM-S4_hsj_XV6nzZot0vM-CeHOaEv8olmgzXj1D5aJ8hPAeC1qml70RhA5zQMkpSZSvW3Pym-p5wxhN6L0KQpawRRkUPTIWFl9JpAmRdrP8nR9E5MCMPVm55DOEN67Rg-CLwQDWn_SVGbCiOBQNPnicGe7Fsgs0n6tI3Y0/file\n",
            "Resolving uc08533c0879967828e6bd675a52.dl.dropboxusercontent.com (uc08533c0879967828e6bd675a52.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to uc08533c0879967828e6bd675a52.dl.dropboxusercontent.com (uc08533c0879967828e6bd675a52.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 986113 (963K) [text/plain]\n",
            "Saving to: ‘LotR.txt.1’\n",
            "\n",
            "LotR.txt.1          100%[===================>] 963.00K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2018-08-27 11:03:28 (12.7 MB/s) - ‘LotR.txt.1’ saved [986113/986113]\n",
            "\n",
            "corpus length: 964203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3k9Vi8cDaiqS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cdd33bb2-44b3-4051-b8a2-5568b8293843"
      },
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "964203"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "Afv5fdebPpw6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "313de32d-346d-499f-f577-9f0323d81add"
      },
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars: 57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Dpy7BpFhPtYx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "69f8fc6c-4d19-47be-f734-adf4e03d7b66"
      },
      "cell_type": "code",
      "source": [
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 321388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BDZyjjuoYhVY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8cbc6bd3-94f9-46a8-b94f-d23f238a2fce"
      },
      "cell_type": "code",
      "source": [
        "print(sentences[0])\n",
        "print(sentences[1])\n",
        "print(sentences[2])\n",
        "print(sentences[3])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿chapter 1 . a long-expected party \n",
            "\n",
            "whe\n",
            "apter 1 . a long-expected party \n",
            "\n",
            "when m\n",
            "er 1 . a long-expected party \n",
            "\n",
            "when mr. \n",
            "1 . a long-expected party \n",
            "\n",
            "when mr. bil\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SyInEpHvPv7k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "216d6bc3-e776-478f-a2df-ffbe718f9861"
      },
      "cell_type": "code",
      "source": [
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lkjUV-hkPwHR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc351803-4c61-4859-eb85-cbf6e8b0bbe5"
      },
      "cell_type": "code",
      "source": [
        "# build the model: a single LSTM\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hMU6lsPcPwO9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IcI8qLxL02Nb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sampling some text from the model"
      ]
    },
    {
      "metadata": {
        "id": "yLhxcB13P4Tf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2vMGH6wAP4hm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def on_epoch_end(epoch, logs):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IbvddKT-QAeq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#callback\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TNrJyLsrPW4z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=60,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I2LK8st0Pip8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3w22IthkPiwu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}